{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feed Forward\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy \n",
    "import pickle\n",
    "from glob import glob\n",
    "import random\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "\n",
    "\"\"\"Change to the data folder\"\"\"\n",
    "new_path = \"./new_train/new_train/\"\n",
    "\n",
    "val_path = \"./new_val_in/new_val_in/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, data_path: str, transform=None):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "\n",
    "        self.pkl_list = glob(os.path.join(self.data_path, '*'))\n",
    "        self.pkl_list.sort()\n",
    "        random.shuffle(self.pkl_list)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pkl_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        pkl_path = self.pkl_list[idx]\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n",
    "    \n",
    "    def capIt(self, a, b):\n",
    "        self.pkl_list = self.pkl_list[a:b]\n",
    "\n",
    "\n",
    "# intialize a dataset\n",
    "train_dataset  = ArgoverseDataset(data_path=new_path)\n",
    "test_dataset = ArgoverseDataset(data_path=new_path)\n",
    "val_dataset  = ArgoverseDataset(data_path=val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.capIt(201000,202008)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.capIt(0,200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000\n",
      "1008\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import math\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "class fcNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self, i_size, o_size, hidden , batchsize):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc_out = nn.Linear(hidden * 2, o_size * 2)\n",
    "        self.fc_hidden = nn.Linear(i_size * 2, hidden * 2)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = self.fc_hidden(x)\n",
    "        out = F.relu(self.fc_out(out))\n",
    "        return out\n",
    "        \n",
    "    def init_hidden(self, batch_size, n_layers, hidden_dim):\n",
    "        hidden = torch.zeros(n_layers, batch_size, hidden_dim).to(device)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 16\n",
    "maxVal = 1500\n",
    "def collateFC(batch):\n",
    "\n",
    "    inp = []\n",
    "    out = []\n",
    "    index = []\n",
    "    for scene in batch:\n",
    "        inp = inp + [[scene['p_in'][i]] for i in range(60) if scene['track_id'][i, 0, 0] == scene['agent_id']]\n",
    "        out = out + [[scene['p_out'][i]] for i in range(60) if scene['track_id'][i, 0, 0] == scene['agent_id']]\n",
    "        index = index + [i for i in range(60) if scene['agent_id'] == scene['track_id'][i, 0, 0]]\n",
    "    inp = torch.FloatTensor(inp).squeeze(1)\n",
    "    out = torch.FloatTensor(out).squeeze(1)\n",
    "\n",
    "    return[inp, out, index]\n",
    "\n",
    "\n",
    "\n",
    "fc_loader = DataLoader(train_dataset,batch_size=batch_sz, shuffle = False, collate_fn=collateFC, num_workers=0)\n",
    "fc_test = DataLoader(test_dataset,batch_size=batch_sz, shuffle = False, collate_fn=collateFC, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch, log_interval=10000):\n",
    "    model.train()\n",
    "    iterator = tqdm(fc_loader, total=int(len(fc_loader)))\n",
    "    counter = 0\n",
    "    for batch_idx, (inp, target, index) in enumerate(iterator):\n",
    "        inp, target = inp.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        a = torch.zeros(1)\n",
    "        inp = inp.reshape(batchSize, -1)\n",
    "        target = target.reshape(batchSize, -1)\n",
    "        \n",
    "        inp = inp/maxVal\n",
    "        target = target/maxVal        \n",
    "        output = model(inp)\n",
    "\n",
    "   \n",
    "        output.to(device)\n",
    "        target.to(device)\n",
    "        loss = criterion(output * maxVal, target * maxVal)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        counter += 1\n",
    "        iterator.set_postfix(loss=(loss.item()*inp.size(0) / (counter * fc_loader.batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    i = 0\n",
    "    with torch.no_grad():\n",
    "        for inp, target, index in fc_test:\n",
    "            inp, target = inp.to(device), target.to(device)\n",
    "            \n",
    "            inp = inp.reshape(batchSize, -1)\n",
    "            target = target.reshape(batchSize, -1)\n",
    "            inp = inp/maxVal\n",
    "            target = target/maxVal\n",
    "            a = torch.zeros(1)\n",
    "            output = model(inp)\n",
    "\n",
    "             #reshape output and target to check loss only on agent car\n",
    "\n",
    "            test_loss += criterion(output * maxVal , target * maxVal)# sum up batch loss\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(fc_test.dataset),\n",
    "        100. * correct / len(fc_test.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSELoss()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.001\n",
    "n_epochs = 5\n",
    "batchSize = 16\n",
    "\n",
    "newModel = fcNetwork(19, 30, 24, 16)\n",
    "newModel = newModel.to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(newModel.parameters(), lr=lr, weight_decay = 1e-4)\n",
    "criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78ce847741af4e41b60b686e8f8c614a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12500.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Test set: Average loss: 28.6860, Accuracy: 0/1008 (0%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff2a6a1482e94cfdb6b0486a455f93b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12500.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Test set: Average loss: 9.4101, Accuracy: 0/1008 (0%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3789c8135a64957adab78da9fc46f64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12500.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Test set: Average loss: 6.0304, Accuracy: 0/1008 (0%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7107ba733a8450182ce1b13472f018b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12500.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Test set: Average loss: 6.1857, Accuracy: 0/1008 (0%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12e6687991f14483b267e3021ffed825",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12500.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Test set: Average loss: 5.1318, Accuracy: 0/1008 (0%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training Run\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    train(newModel, device, fc_loader, optimizer, epoch)\n",
    "    test(newModel, device, fc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 16\n",
    "\n",
    "\n",
    "def collateVal(batch):\n",
    "\n",
    "    inp = []\n",
    "    index = []\n",
    "    scene1 = []\n",
    "    for scene in batch:\n",
    "        inp = inp + [[scene['p_in'][i]] for i in range(60) if scene['track_id'][i, 0, 0] == scene['agent_id']]\n",
    "        index = index + [i for i in range(60) if scene['agent_id'] == scene['track_id'][i, 0, 0]]\n",
    "        scene1 = scene1 + [scene['scene_idx']]\n",
    "    inp = torch.FloatTensor(inp).squeeze(1)\n",
    "\n",
    "    return[inp, index, scene1]\n",
    "\n",
    "\n",
    "\n",
    "val_loader = DataLoader(val_dataset,batch_size=batch_sz, shuffle = True, collate_fn=collateVal, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Writing\n"
     ]
    }
   ],
   "source": [
    "## test file writing\n",
    "import csv\n",
    "\n",
    "\n",
    "\n",
    "header = ['ID','v1','v2','v3','v4','v5','v6','v7','v8','v9','v10','v11','v12','v13','v14','v15','v16','v17','v18',\n",
    "          'v19','v20','v21','v22','v23','v24','v25','v26','v27','v28','v29','v30','v31','v32','v33','v34','v35'\n",
    "          ,'v36','v37','v38','v39','v40','v41','v42','v43','v44','v45','v46','v47','v48','v49','v50','v51','v52',\n",
    "          'v53','v54','v55','v56','v57','v58','v59','v60']\n",
    "\n",
    "with open('./submission.csv', mode = 'w') as f:\n",
    "    writer = csv.writer(f, delimiter=',')\n",
    "    writer.writerow(header)\n",
    "\n",
    "    \n",
    "    \n",
    "    for inp, index, scene in val_loader:\n",
    "        inp  = inp.to(device)\n",
    "        \n",
    "        inp = inp\n",
    "        a = torch.zeros(1)\n",
    "        inp = inp.reshape(batchSize, -1)\n",
    "        output = newModel(inp)\n",
    " \n",
    "         #reshape output and target to check loss only on agent car\n",
    "\n",
    "        for i in range(batch_sz):\n",
    "            writeLine = []\n",
    "            writeLine.append(str(scene[i]))\n",
    "            temp = output.reshape(batch_sz, -1)\n",
    "            \n",
    "            temp = temp[i]\n",
    "            \n",
    "            writeLine = writeLine + temp.tolist()\n",
    "        \n",
    "            if(len(writeLine) != 61):\n",
    "                print(\"list error\")\n",
    "                \n",
    "            writer.writerow(writeLine)\n",
    "            #print(index)\n",
    "        \n",
    "        \n",
    "print(\"Finished Writing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Regresser from SKLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = MLPRegressor(random_state=1, max_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 16\n",
    "def collateFC(batch):\n",
    "\n",
    "    inp = []\n",
    "    out = []\n",
    "    index = []\n",
    "    for scene in batch:\n",
    "        inp = inp + [[scene['p_in'][i]] for i in range(60) if scene['track_id'][i, 0, 0] == scene['agent_id']]\n",
    "        out = out + [[scene['p_out'][i]] for i in range(60) if scene['track_id'][i, 0, 0] == scene['agent_id']]\n",
    "        index = index + [i for i in range(60) if scene['agent_id'] == scene['track_id'][i, 0, 0]]\n",
    "    inp = torch.FloatTensor(inp).squeeze(1)\n",
    "    out = torch.FloatTensor(out).squeeze(1)\n",
    "\n",
    "    return[inp, out, index]\n",
    "\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset,batch_size=batch_sz, shuffle = False, collate_fn=collateFC, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset,batch_size=batch_sz, shuffle = False, collate_fn=collateFC, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:7: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26c8628a6a334abd997996637fc455c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12500.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "x_train = []\n",
    "x_labels = []\n",
    "y_train = []\n",
    "y_labels = []\n",
    "iterator = tqdm(train_loader, total=int(len(train_loader)))\n",
    "for i, [inp, out, index] in enumerate(iterator):\n",
    "    for i in range(batch_sz):\n",
    "        x_train.append(inp.reshape(batch_sz, -1)[i, ::2].tolist())\n",
    "        x_labels.append(out.reshape(batch_sz, -1)[i, ::2].tolist())\n",
    "        y_train.append(inp.reshape(batch_sz, -1)[i, 1::2].tolist())\n",
    "        y_labels.append(out.reshape(batch_sz, -1)[i, 1::2].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "             hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "             learning_rate_init=0.001, max_fun=15000, max_iter=500,\n",
       "             momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "             power_t=0.5, random_state=1, shuffle=True, solver='adam',\n",
       "             tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "             warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.fit(x_train, x_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:7: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4abbdf3b28d45449c8cb229494311bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=63.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "x_test = []\n",
    "y_test = []\n",
    "x_test_labels = []\n",
    "y_test_labels = []\n",
    "iterator = tqdm(test_loader, total=int(len(test_loader)))\n",
    "for i, [inp, out, index] in enumerate(iterator):\n",
    "    for i in range(batch_sz):\n",
    "        x_test.append(inp.reshape(batch_sz, -1)[i, ::2].tolist())\n",
    "        x_test_labels.append(out.reshape(batch_sz, -1)[i, ::2].tolist())\n",
    "        y_test.append(inp.reshape(batch_sz, -1)[i, 1::2].tolist())\n",
    "        y_test_labels.append(out.reshape(batch_sz, -1)[i, 1::2].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/base.py:434: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9999929410770512"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.score(x_test, x_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 16\n",
    "def collateTest(batch):\n",
    "\n",
    "    inp = []\n",
    "    index = []\n",
    "    scene1 = []\n",
    "    for scene in batch:\n",
    "        inp = inp + [[scene['p_in'][i]] for i in range(60) if scene['track_id'][i, 0, 0] == scene['agent_id']]\n",
    "        index = index + [i for i in range(60) if scene['agent_id'] == scene['track_id'][i, 0, 0]]\n",
    "        scene1 = scene1 + [scene['scene_idx']]\n",
    "    inp = torch.FloatTensor(inp).squeeze(1)\n",
    "\n",
    "    return[inp, index, scene1]\n",
    "\n",
    "\n",
    "\n",
    "val_loader = DataLoader(val_dataset,batch_size=batch_sz, shuffle = False, collate_fn=collateTest, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16d697f6f3c14d5f887ffbd02df81c30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=200.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "x_val = []\n",
    "y_val = []\n",
    "sceneOrder = []\n",
    "iterator = tqdm(val_loader, total=int(len(val_loader)))\n",
    "for i, [inp, index, scene] in enumerate(iterator):\n",
    "    for i in range(batch_sz):\n",
    "        x_val.append(inp.reshape(batch_sz, -1)[i, ::2].tolist())\n",
    "        y_val.append(inp.reshape(batch_sz, -1)[i, 1::2].tolist())\n",
    "        sceneOrder.append(scene[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred = regr.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3200"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sceneOrder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "             hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "             learning_rate_init=0.001, max_fun=15000, max_iter=500,\n",
       "             momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "             power_t=0.5, random_state=1, shuffle=True, solver='adam',\n",
       "             tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "             warm_start=False)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr2 = MLPRegressor(random_state=1, max_iter=500)\n",
    "regr2.fit(y_train, y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/base.py:434: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9999623450878169"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr2.score(y_test, y_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regr2.predict(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11528,\n",
       " 21811,\n",
       " 20057,\n",
       " 7040,\n",
       " 12725,\n",
       " 6297,\n",
       " 32423,\n",
       " 26325,\n",
       " 22473,\n",
       " 456,\n",
       " 13382,\n",
       " 34520,\n",
       " 33215,\n",
       " 20363,\n",
       " 28855,\n",
       " 39152,\n",
       " 10019,\n",
       " 12043,\n",
       " 8491,\n",
       " 19771,\n",
       " 36718,\n",
       " 38600,\n",
       " 9707,\n",
       " 34017,\n",
       " 12828,\n",
       " 984,\n",
       " 35773,\n",
       " 19686,\n",
       " 28459,\n",
       " 6478,\n",
       " 18801,\n",
       " 10909,\n",
       " 31882,\n",
       " 36890,\n",
       " 7633,\n",
       " 7784,\n",
       " 35434,\n",
       " 15551,\n",
       " 25715,\n",
       " 18368,\n",
       " 19936,\n",
       " 31818,\n",
       " 25016,\n",
       " 21735,\n",
       " 20887,\n",
       " 8879,\n",
       " 21037,\n",
       " 9836,\n",
       " 24618,\n",
       " 5853,\n",
       " 22197,\n",
       " 977,\n",
       " 12739,\n",
       " 33049,\n",
       " 21209,\n",
       " 16411,\n",
       " 7178,\n",
       " 20302,\n",
       " 15391,\n",
       " 24854,\n",
       " 26415,\n",
       " 9844,\n",
       " 28296,\n",
       " 4611,\n",
       " 21132,\n",
       " 3854,\n",
       " 9262,\n",
       " 36711,\n",
       " 35823,\n",
       " 24764,\n",
       " 25134,\n",
       " 38538,\n",
       " 15459,\n",
       " 31833,\n",
       " 20845,\n",
       " 17276,\n",
       " 3242,\n",
       " 23429,\n",
       " 38717,\n",
       " 25552,\n",
       " 33548,\n",
       " 16441,\n",
       " 28484,\n",
       " 9337,\n",
       " 31969,\n",
       " 3588,\n",
       " 3633,\n",
       " 32864,\n",
       " 968,\n",
       " 15276,\n",
       " 26421,\n",
       " 25566,\n",
       " 18141,\n",
       " 32404,\n",
       " 12867,\n",
       " 4556,\n",
       " 31485,\n",
       " 25028,\n",
       " 23518,\n",
       " 30416,\n",
       " 23281,\n",
       " 23168,\n",
       " 9208,\n",
       " 37751,\n",
       " 4743,\n",
       " 32125,\n",
       " 17273,\n",
       " 24308,\n",
       " 2157,\n",
       " 14357,\n",
       " 34521,\n",
       " 11227,\n",
       " 34150,\n",
       " 27240,\n",
       " 13997,\n",
       " 35657,\n",
       " 12,\n",
       " 27570,\n",
       " 62,\n",
       " 29594,\n",
       " 3250,\n",
       " 30526,\n",
       " 14211,\n",
       " 14511,\n",
       " 16685,\n",
       " 32619,\n",
       " 6261,\n",
       " 33792,\n",
       " 14246,\n",
       " 23670,\n",
       " 26108,\n",
       " 6713,\n",
       " 19150,\n",
       " 10744,\n",
       " 23821,\n",
       " 38550,\n",
       " 34683,\n",
       " 16281,\n",
       " 37043,\n",
       " 32481,\n",
       " 10002,\n",
       " 36059,\n",
       " 21368,\n",
       " 20434,\n",
       " 27392,\n",
       " 33465,\n",
       " 37899,\n",
       " 13067,\n",
       " 30510,\n",
       " 12028,\n",
       " 17091,\n",
       " 7971,\n",
       " 37857,\n",
       " 25995,\n",
       " 23966,\n",
       " 17799,\n",
       " 56,\n",
       " 13507,\n",
       " 3196,\n",
       " 14586,\n",
       " 31156,\n",
       " 7457,\n",
       " 788,\n",
       " 33723,\n",
       " 28716,\n",
       " 9398,\n",
       " 34668,\n",
       " 34993,\n",
       " 37496,\n",
       " 10279,\n",
       " 36208,\n",
       " 15118,\n",
       " 24084,\n",
       " 23144,\n",
       " 39188,\n",
       " 5524,\n",
       " 6135,\n",
       " 2727,\n",
       " 17924,\n",
       " 7328,\n",
       " 28620,\n",
       " 20078,\n",
       " 17916,\n",
       " 27963,\n",
       " 20742,\n",
       " 7227,\n",
       " 19220,\n",
       " 6369,\n",
       " 21763,\n",
       " 28724,\n",
       " 33450,\n",
       " 35764,\n",
       " 23744,\n",
       " 17062,\n",
       " 14392,\n",
       " 13361,\n",
       " 23883,\n",
       " 10662,\n",
       " 24285,\n",
       " 32931,\n",
       " 12901,\n",
       " 5272,\n",
       " 21035,\n",
       " 26610,\n",
       " 16957,\n",
       " 18778,\n",
       " 4244,\n",
       " 30279,\n",
       " 29371,\n",
       " 13819,\n",
       " 7538,\n",
       " 2160,\n",
       " 900,\n",
       " 32734,\n",
       " 6542,\n",
       " 38352,\n",
       " 27811,\n",
       " 16870,\n",
       " 19995,\n",
       " 11474,\n",
       " 9664,\n",
       " 5324,\n",
       " 22039,\n",
       " 25105,\n",
       " 37206,\n",
       " 26011,\n",
       " 9418,\n",
       " 18761,\n",
       " 5913,\n",
       " 25731,\n",
       " 26723,\n",
       " 25189,\n",
       " 38793,\n",
       " 2709,\n",
       " 19956,\n",
       " 17361,\n",
       " 38384,\n",
       " 11152,\n",
       " 16044,\n",
       " 35111,\n",
       " 12494,\n",
       " 17824,\n",
       " 36702,\n",
       " 14058,\n",
       " 36250,\n",
       " 32150,\n",
       " 19741,\n",
       " 35188,\n",
       " 32038,\n",
       " 29931,\n",
       " 14067,\n",
       " 26283,\n",
       " 30948,\n",
       " 11015,\n",
       " 30538,\n",
       " 27032,\n",
       " 10819,\n",
       " 18513,\n",
       " 484,\n",
       " 5566,\n",
       " 24699,\n",
       " 185,\n",
       " 37464,\n",
       " 2296,\n",
       " 37581,\n",
       " 26659,\n",
       " 22678,\n",
       " 27237,\n",
       " 15995,\n",
       " 27860,\n",
       " 31860,\n",
       " 37173,\n",
       " 4681,\n",
       " 28212,\n",
       " 21679,\n",
       " 25891,\n",
       " 13518,\n",
       " 27344,\n",
       " 27065,\n",
       " 39071,\n",
       " 7273,\n",
       " 21975,\n",
       " 37328,\n",
       " 1478,\n",
       " 16189,\n",
       " 38337,\n",
       " 19279,\n",
       " 12900,\n",
       " 1454,\n",
       " 30310,\n",
       " 10535,\n",
       " 35253,\n",
       " 21038,\n",
       " 16949,\n",
       " 29991,\n",
       " 25350,\n",
       " 8750,\n",
       " 10810,\n",
       " 11312,\n",
       " 18763,\n",
       " 33109,\n",
       " 4258,\n",
       " 3083,\n",
       " 7601,\n",
       " 12215,\n",
       " 8756,\n",
       " 2739,\n",
       " 29608,\n",
       " 1350,\n",
       " 15715,\n",
       " 19847,\n",
       " 34516,\n",
       " 21195,\n",
       " 31731,\n",
       " 7330,\n",
       " 30299,\n",
       " 36795,\n",
       " 16723,\n",
       " 13792,\n",
       " 14320,\n",
       " 31418,\n",
       " 2989,\n",
       " 12770,\n",
       " 30718,\n",
       " 19152,\n",
       " 36048,\n",
       " 4201,\n",
       " 14871,\n",
       " 38071,\n",
       " 13932,\n",
       " 12790,\n",
       " 19110,\n",
       " 38762,\n",
       " 3906,\n",
       " 37701,\n",
       " 33597,\n",
       " 12812,\n",
       " 15588,\n",
       " 22191,\n",
       " 30052,\n",
       " 11019,\n",
       " 31734,\n",
       " 8291,\n",
       " 23398,\n",
       " 3947,\n",
       " 38043,\n",
       " 13806,\n",
       " 3453,\n",
       " 26891,\n",
       " 34347,\n",
       " 32616,\n",
       " 11402,\n",
       " 12056,\n",
       " 9101,\n",
       " 24637,\n",
       " 25546,\n",
       " 18565,\n",
       " 1377,\n",
       " 32179,\n",
       " 23161,\n",
       " 25225,\n",
       " 10797,\n",
       " 18770,\n",
       " 356,\n",
       " 18134,\n",
       " 23762,\n",
       " 3843,\n",
       " 33760,\n",
       " 14762,\n",
       " 12300,\n",
       " 28465,\n",
       " 26748,\n",
       " 33971,\n",
       " 18932,\n",
       " 2163,\n",
       " 21365,\n",
       " 37302,\n",
       " 1808,\n",
       " 34229,\n",
       " 15345,\n",
       " 7563,\n",
       " 13325,\n",
       " 37996,\n",
       " 24866,\n",
       " 34797,\n",
       " 8340,\n",
       " 20335,\n",
       " 29358,\n",
       " 22,\n",
       " 8057,\n",
       " 5535,\n",
       " 23072,\n",
       " 27375,\n",
       " 254,\n",
       " 30362,\n",
       " 25172,\n",
       " 1940,\n",
       " 17623,\n",
       " 26336,\n",
       " 31352,\n",
       " 5170,\n",
       " 8176,\n",
       " 2930,\n",
       " 10096,\n",
       " 16035,\n",
       " 14726,\n",
       " 23489,\n",
       " 10078,\n",
       " 22939,\n",
       " 10896,\n",
       " 2607,\n",
       " 30632,\n",
       " 1302,\n",
       " 13446,\n",
       " 2993,\n",
       " 932,\n",
       " 9156,\n",
       " 32772,\n",
       " 28659,\n",
       " 33004,\n",
       " 13136,\n",
       " 19302,\n",
       " 37637,\n",
       " 3897,\n",
       " 5609,\n",
       " 38652,\n",
       " 11621,\n",
       " 14605,\n",
       " 31185,\n",
       " 38501,\n",
       " 17111,\n",
       " 31822,\n",
       " 12593,\n",
       " 125,\n",
       " 38570,\n",
       " 24346,\n",
       " 37721,\n",
       " 12166,\n",
       " 11399,\n",
       " 35580,\n",
       " 6272,\n",
       " 14168,\n",
       " 13384,\n",
       " 33741,\n",
       " 6420,\n",
       " 7263,\n",
       " 12018,\n",
       " 11104,\n",
       " 2700,\n",
       " 4234,\n",
       " 39,\n",
       " 25435,\n",
       " 24161,\n",
       " 11686,\n",
       " 26181,\n",
       " 2383,\n",
       " 12740,\n",
       " 37896,\n",
       " 23036,\n",
       " 3286,\n",
       " 30225,\n",
       " 21820,\n",
       " 16347,\n",
       " 30287,\n",
       " 34494,\n",
       " 30766,\n",
       " 34583,\n",
       " 9532,\n",
       " 36185,\n",
       " 15913,\n",
       " 13645,\n",
       " 21138,\n",
       " 30155,\n",
       " 34052,\n",
       " 34689,\n",
       " 3890,\n",
       " 37922,\n",
       " 38629,\n",
       " 595,\n",
       " 5884,\n",
       " 21243,\n",
       " 35073,\n",
       " 17380,\n",
       " 31060,\n",
       " 36147,\n",
       " 25249,\n",
       " 3294,\n",
       " 2953,\n",
       " 14850,\n",
       " 10816,\n",
       " 24284,\n",
       " 347,\n",
       " 22832,\n",
       " 8112,\n",
       " 23046,\n",
       " 12475,\n",
       " 9838,\n",
       " 26796,\n",
       " 12063,\n",
       " 27790,\n",
       " 33325,\n",
       " 7167,\n",
       " 38116,\n",
       " 14866,\n",
       " 31152,\n",
       " 32932,\n",
       " 6668,\n",
       " 30386,\n",
       " 19588,\n",
       " 1638,\n",
       " 16807,\n",
       " 27626,\n",
       " 2447,\n",
       " 5531,\n",
       " 3740,\n",
       " 8857,\n",
       " 11260,\n",
       " 3096,\n",
       " 29395,\n",
       " 26437,\n",
       " 5848,\n",
       " 35891,\n",
       " 8689,\n",
       " 26341,\n",
       " 11780,\n",
       " 5006,\n",
       " 11713,\n",
       " 38155,\n",
       " 5965,\n",
       " 7590,\n",
       " 32598,\n",
       " 31208,\n",
       " 22647,\n",
       " 25808,\n",
       " 28832,\n",
       " 16042,\n",
       " 23498,\n",
       " 15935,\n",
       " 6072,\n",
       " 33766,\n",
       " 17910,\n",
       " 26456,\n",
       " 15852,\n",
       " 27624,\n",
       " 735,\n",
       " 22132,\n",
       " 731,\n",
       " 19913,\n",
       " 11268,\n",
       " 9731,\n",
       " 39365,\n",
       " 59,\n",
       " 34897,\n",
       " 12016,\n",
       " 26589,\n",
       " 36204,\n",
       " 35984,\n",
       " 37558,\n",
       " 37555,\n",
       " 3916,\n",
       " 13783,\n",
       " 21221,\n",
       " 11739,\n",
       " 21409,\n",
       " 21712,\n",
       " 4417,\n",
       " 8565,\n",
       " 18030,\n",
       " 23648,\n",
       " 17621,\n",
       " 13979,\n",
       " 6254,\n",
       " 13035,\n",
       " 27848,\n",
       " 18268,\n",
       " 38513,\n",
       " 4375,\n",
       " 19073,\n",
       " 20905,\n",
       " 2794,\n",
       " 20521,\n",
       " 6280,\n",
       " 7212,\n",
       " 1961,\n",
       " 21235,\n",
       " 20002,\n",
       " 14269,\n",
       " 15215,\n",
       " 36283,\n",
       " 35748,\n",
       " 21945,\n",
       " 19644,\n",
       " 18100,\n",
       " 37418,\n",
       " 3877,\n",
       " 22725,\n",
       " 19049,\n",
       " 7068,\n",
       " 24957,\n",
       " 15738,\n",
       " 35498,\n",
       " 30778,\n",
       " 28151,\n",
       " 25639,\n",
       " 7703,\n",
       " 20641,\n",
       " 22047,\n",
       " 5497,\n",
       " 16336,\n",
       " 3313,\n",
       " 26804,\n",
       " 21099,\n",
       " 8741,\n",
       " 16918,\n",
       " 27377,\n",
       " 11962,\n",
       " 592,\n",
       " 7544,\n",
       " 38758,\n",
       " 14516,\n",
       " 38485,\n",
       " 10069,\n",
       " 21448,\n",
       " 36586,\n",
       " 11681,\n",
       " 16987,\n",
       " 25957,\n",
       " 17699,\n",
       " 31482,\n",
       " 37025,\n",
       " 35815,\n",
       " 14590,\n",
       " 20375,\n",
       " 5657,\n",
       " 37384,\n",
       " 1463,\n",
       " 38303,\n",
       " 35048,\n",
       " 23014,\n",
       " 29539,\n",
       " 3927,\n",
       " 28408,\n",
       " 1516,\n",
       " 15871,\n",
       " 21261,\n",
       " 36313,\n",
       " 36781,\n",
       " 10200,\n",
       " 20859,\n",
       " 943,\n",
       " 35701,\n",
       " 36328,\n",
       " 4338,\n",
       " 24554,\n",
       " 24679,\n",
       " 17905,\n",
       " 5123,\n",
       " 15511,\n",
       " 14547,\n",
       " 10161,\n",
       " 585,\n",
       " 31723,\n",
       " 4773,\n",
       " 7123,\n",
       " 509,\n",
       " 8345,\n",
       " 28114,\n",
       " 12234,\n",
       " 19303,\n",
       " 6001,\n",
       " 30872,\n",
       " 24332,\n",
       " 1579,\n",
       " 30544,\n",
       " 31469,\n",
       " 22270,\n",
       " 1076,\n",
       " 1137,\n",
       " 816,\n",
       " 1181,\n",
       " 34599,\n",
       " 32329,\n",
       " 4232,\n",
       " 455,\n",
       " 28797,\n",
       " 33872,\n",
       " 4867,\n",
       " 10561,\n",
       " 9514,\n",
       " 8867,\n",
       " 35144,\n",
       " 36817,\n",
       " 38990,\n",
       " 11807,\n",
       " 19574,\n",
       " 5552,\n",
       " 8514,\n",
       " 20246,\n",
       " 6894,\n",
       " 35805,\n",
       " 30594,\n",
       " 37127,\n",
       " 15036,\n",
       " 44,\n",
       " 13195,\n",
       " 12502,\n",
       " 5751,\n",
       " 14709,\n",
       " 9678,\n",
       " 24735,\n",
       " 17326,\n",
       " 19569,\n",
       " 31617,\n",
       " 27128,\n",
       " 6017,\n",
       " 9780,\n",
       " 29326,\n",
       " 37841,\n",
       " 4558,\n",
       " 32290,\n",
       " 22018,\n",
       " 1587,\n",
       " 24366,\n",
       " 12531,\n",
       " 3889,\n",
       " 27507,\n",
       " 503,\n",
       " 29264,\n",
       " 29528,\n",
       " 15901,\n",
       " 36149,\n",
       " 10521,\n",
       " 39030,\n",
       " 28996,\n",
       " 20052,\n",
       " 2382,\n",
       " 3318,\n",
       " 18061,\n",
       " 27416,\n",
       " 5505,\n",
       " 15522,\n",
       " 14255,\n",
       " 31705,\n",
       " 31762,\n",
       " 19281,\n",
       " 10413,\n",
       " 15928,\n",
       " 15109,\n",
       " 23642,\n",
       " 12169,\n",
       " 23288,\n",
       " 27259,\n",
       " 17815,\n",
       " 11556,\n",
       " 23297,\n",
       " 22620,\n",
       " 4401,\n",
       " 26835,\n",
       " 9751,\n",
       " 29119,\n",
       " 38657,\n",
       " 27108,\n",
       " 7540,\n",
       " 10165,\n",
       " 34823,\n",
       " 23027,\n",
       " 33596,\n",
       " 8971,\n",
       " 14125,\n",
       " 17769,\n",
       " 17884,\n",
       " 30246,\n",
       " 18535,\n",
       " 6471,\n",
       " 10916,\n",
       " 34232,\n",
       " 18176,\n",
       " 11281,\n",
       " 33823,\n",
       " 908,\n",
       " 16741,\n",
       " 32733,\n",
       " 11450,\n",
       " 33599,\n",
       " 37378,\n",
       " 13121,\n",
       " 5448,\n",
       " 17359,\n",
       " 25830,\n",
       " 12979,\n",
       " 6961,\n",
       " 10951,\n",
       " 28641,\n",
       " 8477,\n",
       " 15491,\n",
       " 18400,\n",
       " 8930,\n",
       " 29638,\n",
       " 32347,\n",
       " 21092,\n",
       " 5734,\n",
       " 27183,\n",
       " 27908,\n",
       " 18089,\n",
       " 16561,\n",
       " 15475,\n",
       " 18055,\n",
       " 26800,\n",
       " 7415,\n",
       " 3866,\n",
       " 14175,\n",
       " 21864,\n",
       " 29983,\n",
       " 10646,\n",
       " 32227,\n",
       " 14569,\n",
       " 12641,\n",
       " 6049,\n",
       " 32340,\n",
       " 38614,\n",
       " 30571,\n",
       " 32447,\n",
       " 10828,\n",
       " 2111,\n",
       " 6405,\n",
       " 34368,\n",
       " 34098,\n",
       " 25549,\n",
       " 8726,\n",
       " 21966,\n",
       " 34661,\n",
       " 13042,\n",
       " 12870,\n",
       " 37904,\n",
       " 37172,\n",
       " 4051,\n",
       " 37246,\n",
       " 27187,\n",
       " 11039,\n",
       " 38946,\n",
       " 34331,\n",
       " 1728,\n",
       " 22271,\n",
       " 20166,\n",
       " 16121,\n",
       " 30234,\n",
       " 892,\n",
       " 20538,\n",
       " 5909,\n",
       " 33150,\n",
       " 27236,\n",
       " 10605,\n",
       " 32443,\n",
       " 18805,\n",
       " 30711,\n",
       " 11211,\n",
       " 19660,\n",
       " 20144,\n",
       " 27847,\n",
       " 30082,\n",
       " 23262,\n",
       " 28070,\n",
       " 3541,\n",
       " 20216,\n",
       " 31076,\n",
       " 1548,\n",
       " 35736,\n",
       " 39281,\n",
       " 16808,\n",
       " 37073,\n",
       " 36633,\n",
       " 35276,\n",
       " 2440,\n",
       " 31405,\n",
       " 22895,\n",
       " 31754,\n",
       " 12679,\n",
       " 15273,\n",
       " 4318,\n",
       " 33930,\n",
       " 3113,\n",
       " 30547,\n",
       " 19295,\n",
       " 31345,\n",
       " 3767,\n",
       " 11381,\n",
       " 5700,\n",
       " 19333,\n",
       " 7701,\n",
       " 3558,\n",
       " 26140,\n",
       " 4340,\n",
       " 21557,\n",
       " 32141,\n",
       " 18051,\n",
       " 24019,\n",
       " 15533,\n",
       " 21629,\n",
       " 13749,\n",
       " 11893,\n",
       " 16220,\n",
       " 773,\n",
       " 3853,\n",
       " 4180,\n",
       " 5759,\n",
       " 20847,\n",
       " 241,\n",
       " 13961,\n",
       " 27168,\n",
       " 28067,\n",
       " 25725,\n",
       " 15446,\n",
       " 29168,\n",
       " 33,\n",
       " 26322,\n",
       " 33668,\n",
       " 19310,\n",
       " 37123,\n",
       " 13648,\n",
       " 23231,\n",
       " 5066,\n",
       " 19706,\n",
       " 16701,\n",
       " 30080,\n",
       " 39428,\n",
       " 8310,\n",
       " 28476,\n",
       " 35971,\n",
       " 3158,\n",
       " 20312,\n",
       " 21682,\n",
       " 38460,\n",
       " 6170,\n",
       " 4339,\n",
       " 36800,\n",
       " 14048,\n",
       " 1151,\n",
       " 8188,\n",
       " 22812,\n",
       " 8983,\n",
       " 36414,\n",
       " 12981,\n",
       " 15441,\n",
       " 8435,\n",
       " 37433,\n",
       " 16036,\n",
       " 37795,\n",
       " 23228,\n",
       " 31656,\n",
       " 9016,\n",
       " 22298,\n",
       " 14510,\n",
       " 24758,\n",
       " 7766,\n",
       " 20914,\n",
       " 19445,\n",
       " 28912,\n",
       " 7946,\n",
       " 16974,\n",
       " 7157,\n",
       " 37070,\n",
       " 15667,\n",
       " 29705,\n",
       " 30546,\n",
       " 7054,\n",
       " 25455,\n",
       " 7495,\n",
       " 4071,\n",
       " 19405,\n",
       " 942,\n",
       " 2598,\n",
       " 7172,\n",
       " 39404,\n",
       " 22095,\n",
       " 22081,\n",
       " 30515,\n",
       " 6634,\n",
       " 17016,\n",
       " 3981,\n",
       " 32955,\n",
       " 18024,\n",
       " 19508,\n",
       " 33826,\n",
       " 30026,\n",
       " 32508,\n",
       " 25066,\n",
       " 33365,\n",
       " 38336,\n",
       " 9481,\n",
       " 10750,\n",
       " 20514,\n",
       " 31581,\n",
       " 28877,\n",
       " 36818,\n",
       " 27718,\n",
       " 33035,\n",
       " 26776,\n",
       " 881,\n",
       " 1832,\n",
       " 26067,\n",
       " ...]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sceneOrder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11528</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21811</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20057</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7040</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12725</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3195</th>\n",
       "      <td>16905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3196</th>\n",
       "      <td>28089</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3197</th>\n",
       "      <td>6857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3198</th>\n",
       "      <td>16152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3199</th>\n",
       "      <td>4523</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3200 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0    1    2    3    4    5    6    7    8    9   ...   51   52   53  \\\n",
       "0     11528  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
       "1     21811  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
       "2     20057  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
       "3      7040  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
       "4     12725  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
       "...     ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "3195  16905  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
       "3196  28089  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
       "3197   6857  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
       "3198  16152  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
       "3199   4523  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
       "\n",
       "       54   55   56   57   58   59   60  \n",
       "0     NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "1     NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "2     NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "3     NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "4     NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "...   ...  ...  ...  ...  ...  ...  ...  \n",
       "3195  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "3196  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "3197  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "3198  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "3199  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "\n",
       "[3200 rows x 61 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dfc = pd.DataFrame(columns=np.arange(61))\n",
    "dfc[0] = list(sceneOrder)\n",
    "dfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1881.73164028, 1879.92807411, 1878.23778084, 1878.29725071,\n",
       "       1877.23252327, 1876.02236407, 1875.27236834, 1875.56675537,\n",
       "       1873.22633314, 1871.74831349, 1871.42963322, 1870.18339108,\n",
       "       1869.41651461, 1869.39937392, 1867.53540196, 1867.04908077,\n",
       "       1865.79775967, 1866.35007988, 1864.56666823, 1863.15587558,\n",
       "       1862.25597992, 1861.77892016, 1861.02735184, 1860.00247667,\n",
       "       1858.00110568, 1858.26733218, 1856.21930268, 1856.55248921,\n",
       "       1855.58248574, 1855.68861905])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([486.03842717, 485.22602599, 484.91678638, 483.60740775,\n",
       "       483.55512378, 482.33708484, 483.03563836, 482.54847685,\n",
       "       481.15359872, 480.21359941, 479.45981897, 479.21355794,\n",
       "       478.22688429, 477.82158985, 477.41905246, 477.69165354,\n",
       "       476.43084328, 475.97100509, 475.71066906, 474.34527937,\n",
       "       474.5781366 , 473.26888016, 472.66814252, 471.62088233,\n",
       "       470.89379099, 470.84138041, 469.39396854, 470.44456683,\n",
       "       469.98686338, 468.64036001])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,30):\n",
    "    dfc[(i * 2) + 1] = x_pred[:, i]\n",
    "    dfc[(2 * i) + 2] = y_pred[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11528</td>\n",
       "      <td>1881.731640</td>\n",
       "      <td>486.038427</td>\n",
       "      <td>1879.928074</td>\n",
       "      <td>485.226026</td>\n",
       "      <td>1878.237781</td>\n",
       "      <td>484.916786</td>\n",
       "      <td>1878.297251</td>\n",
       "      <td>483.607408</td>\n",
       "      <td>1877.232523</td>\n",
       "      <td>...</td>\n",
       "      <td>1858.267332</td>\n",
       "      <td>470.841380</td>\n",
       "      <td>1856.219303</td>\n",
       "      <td>469.393969</td>\n",
       "      <td>1856.552489</td>\n",
       "      <td>470.444567</td>\n",
       "      <td>1855.582486</td>\n",
       "      <td>469.986863</td>\n",
       "      <td>1855.688619</td>\n",
       "      <td>468.640360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21811</td>\n",
       "      <td>254.708490</td>\n",
       "      <td>1039.872984</td>\n",
       "      <td>254.585627</td>\n",
       "      <td>1038.889137</td>\n",
       "      <td>254.594566</td>\n",
       "      <td>1037.701746</td>\n",
       "      <td>254.783283</td>\n",
       "      <td>1036.928615</td>\n",
       "      <td>254.764632</td>\n",
       "      <td>...</td>\n",
       "      <td>255.513024</td>\n",
       "      <td>1018.542852</td>\n",
       "      <td>255.457484</td>\n",
       "      <td>1017.695371</td>\n",
       "      <td>255.634974</td>\n",
       "      <td>1016.850498</td>\n",
       "      <td>255.686676</td>\n",
       "      <td>1016.130810</td>\n",
       "      <td>255.772308</td>\n",
       "      <td>1014.982323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20057</td>\n",
       "      <td>2155.943395</td>\n",
       "      <td>709.099298</td>\n",
       "      <td>2154.467422</td>\n",
       "      <td>708.568434</td>\n",
       "      <td>2153.116022</td>\n",
       "      <td>707.799349</td>\n",
       "      <td>2153.609894</td>\n",
       "      <td>707.412619</td>\n",
       "      <td>2152.675959</td>\n",
       "      <td>...</td>\n",
       "      <td>2141.261714</td>\n",
       "      <td>697.260472</td>\n",
       "      <td>2139.560668</td>\n",
       "      <td>696.809420</td>\n",
       "      <td>2140.308635</td>\n",
       "      <td>696.350739</td>\n",
       "      <td>2139.635565</td>\n",
       "      <td>695.975627</td>\n",
       "      <td>2140.150727</td>\n",
       "      <td>695.287165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7040</td>\n",
       "      <td>201.537699</td>\n",
       "      <td>1535.678036</td>\n",
       "      <td>202.336697</td>\n",
       "      <td>1535.080775</td>\n",
       "      <td>202.712908</td>\n",
       "      <td>1534.049328</td>\n",
       "      <td>203.145452</td>\n",
       "      <td>1533.703812</td>\n",
       "      <td>204.116087</td>\n",
       "      <td>...</td>\n",
       "      <td>214.686196</td>\n",
       "      <td>1522.173753</td>\n",
       "      <td>214.943301</td>\n",
       "      <td>1521.623641</td>\n",
       "      <td>215.417004</td>\n",
       "      <td>1521.138921</td>\n",
       "      <td>215.592934</td>\n",
       "      <td>1520.721280</td>\n",
       "      <td>215.539759</td>\n",
       "      <td>1519.745928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12725</td>\n",
       "      <td>249.444091</td>\n",
       "      <td>1187.685341</td>\n",
       "      <td>249.306445</td>\n",
       "      <td>1186.087956</td>\n",
       "      <td>249.328818</td>\n",
       "      <td>1184.648237</td>\n",
       "      <td>249.536132</td>\n",
       "      <td>1183.043804</td>\n",
       "      <td>249.559171</td>\n",
       "      <td>...</td>\n",
       "      <td>250.708801</td>\n",
       "      <td>1155.998251</td>\n",
       "      <td>250.527023</td>\n",
       "      <td>1154.416109</td>\n",
       "      <td>250.811362</td>\n",
       "      <td>1153.720921</td>\n",
       "      <td>250.932460</td>\n",
       "      <td>1152.601370</td>\n",
       "      <td>250.994598</td>\n",
       "      <td>1150.809199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3195</th>\n",
       "      <td>16905</td>\n",
       "      <td>577.724882</td>\n",
       "      <td>1380.802520</td>\n",
       "      <td>577.452172</td>\n",
       "      <td>1380.104572</td>\n",
       "      <td>577.339700</td>\n",
       "      <td>1379.270221</td>\n",
       "      <td>577.610687</td>\n",
       "      <td>1378.841858</td>\n",
       "      <td>577.500031</td>\n",
       "      <td>...</td>\n",
       "      <td>577.284505</td>\n",
       "      <td>1368.610978</td>\n",
       "      <td>576.965026</td>\n",
       "      <td>1367.950790</td>\n",
       "      <td>577.278280</td>\n",
       "      <td>1367.584677</td>\n",
       "      <td>577.261276</td>\n",
       "      <td>1367.221699</td>\n",
       "      <td>577.468860</td>\n",
       "      <td>1366.473056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3196</th>\n",
       "      <td>28089</td>\n",
       "      <td>586.645465</td>\n",
       "      <td>1379.399500</td>\n",
       "      <td>586.368776</td>\n",
       "      <td>1380.394807</td>\n",
       "      <td>586.242682</td>\n",
       "      <td>1381.219545</td>\n",
       "      <td>586.563523</td>\n",
       "      <td>1382.421676</td>\n",
       "      <td>586.494351</td>\n",
       "      <td>...</td>\n",
       "      <td>587.277700</td>\n",
       "      <td>1408.285285</td>\n",
       "      <td>587.050579</td>\n",
       "      <td>1409.381164</td>\n",
       "      <td>587.417059</td>\n",
       "      <td>1410.319995</td>\n",
       "      <td>587.471244</td>\n",
       "      <td>1411.495963</td>\n",
       "      <td>587.665562</td>\n",
       "      <td>1412.260669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3197</th>\n",
       "      <td>6857</td>\n",
       "      <td>597.217246</td>\n",
       "      <td>1527.064490</td>\n",
       "      <td>596.686452</td>\n",
       "      <td>1527.016874</td>\n",
       "      <td>596.350725</td>\n",
       "      <td>1526.527276</td>\n",
       "      <td>596.472419</td>\n",
       "      <td>1526.807906</td>\n",
       "      <td>596.089304</td>\n",
       "      <td>...</td>\n",
       "      <td>592.180505</td>\n",
       "      <td>1528.450841</td>\n",
       "      <td>591.825208</td>\n",
       "      <td>1528.542128</td>\n",
       "      <td>591.854611</td>\n",
       "      <td>1528.538372</td>\n",
       "      <td>591.601316</td>\n",
       "      <td>1528.647933</td>\n",
       "      <td>591.734306</td>\n",
       "      <td>1528.216409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3198</th>\n",
       "      <td>16152</td>\n",
       "      <td>1745.845307</td>\n",
       "      <td>469.177597</td>\n",
       "      <td>1744.497498</td>\n",
       "      <td>468.534756</td>\n",
       "      <td>1742.896187</td>\n",
       "      <td>468.133884</td>\n",
       "      <td>1743.119558</td>\n",
       "      <td>467.242674</td>\n",
       "      <td>1742.227691</td>\n",
       "      <td>...</td>\n",
       "      <td>1726.336609</td>\n",
       "      <td>455.579601</td>\n",
       "      <td>1724.443274</td>\n",
       "      <td>454.601886</td>\n",
       "      <td>1725.104752</td>\n",
       "      <td>455.027369</td>\n",
       "      <td>1724.272582</td>\n",
       "      <td>454.714193</td>\n",
       "      <td>1724.361497</td>\n",
       "      <td>453.652381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3199</th>\n",
       "      <td>4523</td>\n",
       "      <td>1988.686107</td>\n",
       "      <td>572.971326</td>\n",
       "      <td>1986.988109</td>\n",
       "      <td>572.220733</td>\n",
       "      <td>1985.476285</td>\n",
       "      <td>571.546164</td>\n",
       "      <td>1985.628877</td>\n",
       "      <td>570.733403</td>\n",
       "      <td>1984.478573</td>\n",
       "      <td>...</td>\n",
       "      <td>1967.803791</td>\n",
       "      <td>557.467547</td>\n",
       "      <td>1965.896364</td>\n",
       "      <td>556.623033</td>\n",
       "      <td>1966.254468</td>\n",
       "      <td>556.517922</td>\n",
       "      <td>1965.271000</td>\n",
       "      <td>556.010473</td>\n",
       "      <td>1965.609573</td>\n",
       "      <td>554.975151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3200 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0            1            2            3            4            5   \\\n",
       "0     11528  1881.731640   486.038427  1879.928074   485.226026  1878.237781   \n",
       "1     21811   254.708490  1039.872984   254.585627  1038.889137   254.594566   \n",
       "2     20057  2155.943395   709.099298  2154.467422   708.568434  2153.116022   \n",
       "3      7040   201.537699  1535.678036   202.336697  1535.080775   202.712908   \n",
       "4     12725   249.444091  1187.685341   249.306445  1186.087956   249.328818   \n",
       "...     ...          ...          ...          ...          ...          ...   \n",
       "3195  16905   577.724882  1380.802520   577.452172  1380.104572   577.339700   \n",
       "3196  28089   586.645465  1379.399500   586.368776  1380.394807   586.242682   \n",
       "3197   6857   597.217246  1527.064490   596.686452  1527.016874   596.350725   \n",
       "3198  16152  1745.845307   469.177597  1744.497498   468.534756  1742.896187   \n",
       "3199   4523  1988.686107   572.971326  1986.988109   572.220733  1985.476285   \n",
       "\n",
       "               6            7            8            9   ...           51  \\\n",
       "0      484.916786  1878.297251   483.607408  1877.232523  ...  1858.267332   \n",
       "1     1037.701746   254.783283  1036.928615   254.764632  ...   255.513024   \n",
       "2      707.799349  2153.609894   707.412619  2152.675959  ...  2141.261714   \n",
       "3     1534.049328   203.145452  1533.703812   204.116087  ...   214.686196   \n",
       "4     1184.648237   249.536132  1183.043804   249.559171  ...   250.708801   \n",
       "...           ...          ...          ...          ...  ...          ...   \n",
       "3195  1379.270221   577.610687  1378.841858   577.500031  ...   577.284505   \n",
       "3196  1381.219545   586.563523  1382.421676   586.494351  ...   587.277700   \n",
       "3197  1526.527276   596.472419  1526.807906   596.089304  ...   592.180505   \n",
       "3198   468.133884  1743.119558   467.242674  1742.227691  ...  1726.336609   \n",
       "3199   571.546164  1985.628877   570.733403  1984.478573  ...  1967.803791   \n",
       "\n",
       "               52           53           54           55           56  \\\n",
       "0      470.841380  1856.219303   469.393969  1856.552489   470.444567   \n",
       "1     1018.542852   255.457484  1017.695371   255.634974  1016.850498   \n",
       "2      697.260472  2139.560668   696.809420  2140.308635   696.350739   \n",
       "3     1522.173753   214.943301  1521.623641   215.417004  1521.138921   \n",
       "4     1155.998251   250.527023  1154.416109   250.811362  1153.720921   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "3195  1368.610978   576.965026  1367.950790   577.278280  1367.584677   \n",
       "3196  1408.285285   587.050579  1409.381164   587.417059  1410.319995   \n",
       "3197  1528.450841   591.825208  1528.542128   591.854611  1528.538372   \n",
       "3198   455.579601  1724.443274   454.601886  1725.104752   455.027369   \n",
       "3199   557.467547  1965.896364   556.623033  1966.254468   556.517922   \n",
       "\n",
       "               57           58           59           60  \n",
       "0     1855.582486   469.986863  1855.688619   468.640360  \n",
       "1      255.686676  1016.130810   255.772308  1014.982323  \n",
       "2     2139.635565   695.975627  2140.150727   695.287165  \n",
       "3      215.592934  1520.721280   215.539759  1519.745928  \n",
       "4      250.932460  1152.601370   250.994598  1150.809199  \n",
       "...           ...          ...          ...          ...  \n",
       "3195   577.261276  1367.221699   577.468860  1366.473056  \n",
       "3196   587.471244  1411.495963   587.665562  1412.260669  \n",
       "3197   591.601316  1528.647933   591.734306  1528.216409  \n",
       "3198  1724.272582   454.714193  1724.361497   453.652381  \n",
       "3199  1965.271000   556.010473  1965.609573   554.975151  \n",
       "\n",
       "[3200 rows x 61 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = ['ID','v1','v2','v3','v4','v5','v6','v7','v8','v9','v10','v11','v12','v13','v14','v15','v16','v17','v18',\n",
    "          'v19','v20','v21','v22','v23','v24','v25','v26','v27','v28','v29','v30','v31','v32','v33','v34','v35'\n",
    "          ,'v36','v37','v38','v39','v40','v41','v42','v43','v44','v45','v46','v47','v48','v49','v50','v51','v52',\n",
    "          'v53','v54','v55','v56','v57','v58','v59','v60']\n",
    "dfc.columns = (header )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>v9</th>\n",
       "      <th>...</th>\n",
       "      <th>v51</th>\n",
       "      <th>v52</th>\n",
       "      <th>v53</th>\n",
       "      <th>v54</th>\n",
       "      <th>v55</th>\n",
       "      <th>v56</th>\n",
       "      <th>v57</th>\n",
       "      <th>v58</th>\n",
       "      <th>v59</th>\n",
       "      <th>v60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11528</td>\n",
       "      <td>1881.731640</td>\n",
       "      <td>486.038427</td>\n",
       "      <td>1879.928074</td>\n",
       "      <td>485.226026</td>\n",
       "      <td>1878.237781</td>\n",
       "      <td>484.916786</td>\n",
       "      <td>1878.297251</td>\n",
       "      <td>483.607408</td>\n",
       "      <td>1877.232523</td>\n",
       "      <td>...</td>\n",
       "      <td>1858.267332</td>\n",
       "      <td>470.841380</td>\n",
       "      <td>1856.219303</td>\n",
       "      <td>469.393969</td>\n",
       "      <td>1856.552489</td>\n",
       "      <td>470.444567</td>\n",
       "      <td>1855.582486</td>\n",
       "      <td>469.986863</td>\n",
       "      <td>1855.688619</td>\n",
       "      <td>468.640360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21811</td>\n",
       "      <td>254.708490</td>\n",
       "      <td>1039.872984</td>\n",
       "      <td>254.585627</td>\n",
       "      <td>1038.889137</td>\n",
       "      <td>254.594566</td>\n",
       "      <td>1037.701746</td>\n",
       "      <td>254.783283</td>\n",
       "      <td>1036.928615</td>\n",
       "      <td>254.764632</td>\n",
       "      <td>...</td>\n",
       "      <td>255.513024</td>\n",
       "      <td>1018.542852</td>\n",
       "      <td>255.457484</td>\n",
       "      <td>1017.695371</td>\n",
       "      <td>255.634974</td>\n",
       "      <td>1016.850498</td>\n",
       "      <td>255.686676</td>\n",
       "      <td>1016.130810</td>\n",
       "      <td>255.772308</td>\n",
       "      <td>1014.982323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20057</td>\n",
       "      <td>2155.943395</td>\n",
       "      <td>709.099298</td>\n",
       "      <td>2154.467422</td>\n",
       "      <td>708.568434</td>\n",
       "      <td>2153.116022</td>\n",
       "      <td>707.799349</td>\n",
       "      <td>2153.609894</td>\n",
       "      <td>707.412619</td>\n",
       "      <td>2152.675959</td>\n",
       "      <td>...</td>\n",
       "      <td>2141.261714</td>\n",
       "      <td>697.260472</td>\n",
       "      <td>2139.560668</td>\n",
       "      <td>696.809420</td>\n",
       "      <td>2140.308635</td>\n",
       "      <td>696.350739</td>\n",
       "      <td>2139.635565</td>\n",
       "      <td>695.975627</td>\n",
       "      <td>2140.150727</td>\n",
       "      <td>695.287165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7040</td>\n",
       "      <td>201.537699</td>\n",
       "      <td>1535.678036</td>\n",
       "      <td>202.336697</td>\n",
       "      <td>1535.080775</td>\n",
       "      <td>202.712908</td>\n",
       "      <td>1534.049328</td>\n",
       "      <td>203.145452</td>\n",
       "      <td>1533.703812</td>\n",
       "      <td>204.116087</td>\n",
       "      <td>...</td>\n",
       "      <td>214.686196</td>\n",
       "      <td>1522.173753</td>\n",
       "      <td>214.943301</td>\n",
       "      <td>1521.623641</td>\n",
       "      <td>215.417004</td>\n",
       "      <td>1521.138921</td>\n",
       "      <td>215.592934</td>\n",
       "      <td>1520.721280</td>\n",
       "      <td>215.539759</td>\n",
       "      <td>1519.745928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12725</td>\n",
       "      <td>249.444091</td>\n",
       "      <td>1187.685341</td>\n",
       "      <td>249.306445</td>\n",
       "      <td>1186.087956</td>\n",
       "      <td>249.328818</td>\n",
       "      <td>1184.648237</td>\n",
       "      <td>249.536132</td>\n",
       "      <td>1183.043804</td>\n",
       "      <td>249.559171</td>\n",
       "      <td>...</td>\n",
       "      <td>250.708801</td>\n",
       "      <td>1155.998251</td>\n",
       "      <td>250.527023</td>\n",
       "      <td>1154.416109</td>\n",
       "      <td>250.811362</td>\n",
       "      <td>1153.720921</td>\n",
       "      <td>250.932460</td>\n",
       "      <td>1152.601370</td>\n",
       "      <td>250.994598</td>\n",
       "      <td>1150.809199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3195</th>\n",
       "      <td>16905</td>\n",
       "      <td>577.724882</td>\n",
       "      <td>1380.802520</td>\n",
       "      <td>577.452172</td>\n",
       "      <td>1380.104572</td>\n",
       "      <td>577.339700</td>\n",
       "      <td>1379.270221</td>\n",
       "      <td>577.610687</td>\n",
       "      <td>1378.841858</td>\n",
       "      <td>577.500031</td>\n",
       "      <td>...</td>\n",
       "      <td>577.284505</td>\n",
       "      <td>1368.610978</td>\n",
       "      <td>576.965026</td>\n",
       "      <td>1367.950790</td>\n",
       "      <td>577.278280</td>\n",
       "      <td>1367.584677</td>\n",
       "      <td>577.261276</td>\n",
       "      <td>1367.221699</td>\n",
       "      <td>577.468860</td>\n",
       "      <td>1366.473056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3196</th>\n",
       "      <td>28089</td>\n",
       "      <td>586.645465</td>\n",
       "      <td>1379.399500</td>\n",
       "      <td>586.368776</td>\n",
       "      <td>1380.394807</td>\n",
       "      <td>586.242682</td>\n",
       "      <td>1381.219545</td>\n",
       "      <td>586.563523</td>\n",
       "      <td>1382.421676</td>\n",
       "      <td>586.494351</td>\n",
       "      <td>...</td>\n",
       "      <td>587.277700</td>\n",
       "      <td>1408.285285</td>\n",
       "      <td>587.050579</td>\n",
       "      <td>1409.381164</td>\n",
       "      <td>587.417059</td>\n",
       "      <td>1410.319995</td>\n",
       "      <td>587.471244</td>\n",
       "      <td>1411.495963</td>\n",
       "      <td>587.665562</td>\n",
       "      <td>1412.260669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3197</th>\n",
       "      <td>6857</td>\n",
       "      <td>597.217246</td>\n",
       "      <td>1527.064490</td>\n",
       "      <td>596.686452</td>\n",
       "      <td>1527.016874</td>\n",
       "      <td>596.350725</td>\n",
       "      <td>1526.527276</td>\n",
       "      <td>596.472419</td>\n",
       "      <td>1526.807906</td>\n",
       "      <td>596.089304</td>\n",
       "      <td>...</td>\n",
       "      <td>592.180505</td>\n",
       "      <td>1528.450841</td>\n",
       "      <td>591.825208</td>\n",
       "      <td>1528.542128</td>\n",
       "      <td>591.854611</td>\n",
       "      <td>1528.538372</td>\n",
       "      <td>591.601316</td>\n",
       "      <td>1528.647933</td>\n",
       "      <td>591.734306</td>\n",
       "      <td>1528.216409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3198</th>\n",
       "      <td>16152</td>\n",
       "      <td>1745.845307</td>\n",
       "      <td>469.177597</td>\n",
       "      <td>1744.497498</td>\n",
       "      <td>468.534756</td>\n",
       "      <td>1742.896187</td>\n",
       "      <td>468.133884</td>\n",
       "      <td>1743.119558</td>\n",
       "      <td>467.242674</td>\n",
       "      <td>1742.227691</td>\n",
       "      <td>...</td>\n",
       "      <td>1726.336609</td>\n",
       "      <td>455.579601</td>\n",
       "      <td>1724.443274</td>\n",
       "      <td>454.601886</td>\n",
       "      <td>1725.104752</td>\n",
       "      <td>455.027369</td>\n",
       "      <td>1724.272582</td>\n",
       "      <td>454.714193</td>\n",
       "      <td>1724.361497</td>\n",
       "      <td>453.652381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3199</th>\n",
       "      <td>4523</td>\n",
       "      <td>1988.686107</td>\n",
       "      <td>572.971326</td>\n",
       "      <td>1986.988109</td>\n",
       "      <td>572.220733</td>\n",
       "      <td>1985.476285</td>\n",
       "      <td>571.546164</td>\n",
       "      <td>1985.628877</td>\n",
       "      <td>570.733403</td>\n",
       "      <td>1984.478573</td>\n",
       "      <td>...</td>\n",
       "      <td>1967.803791</td>\n",
       "      <td>557.467547</td>\n",
       "      <td>1965.896364</td>\n",
       "      <td>556.623033</td>\n",
       "      <td>1966.254468</td>\n",
       "      <td>556.517922</td>\n",
       "      <td>1965.271000</td>\n",
       "      <td>556.010473</td>\n",
       "      <td>1965.609573</td>\n",
       "      <td>554.975151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3200 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID           v1           v2           v3           v4           v5  \\\n",
       "0     11528  1881.731640   486.038427  1879.928074   485.226026  1878.237781   \n",
       "1     21811   254.708490  1039.872984   254.585627  1038.889137   254.594566   \n",
       "2     20057  2155.943395   709.099298  2154.467422   708.568434  2153.116022   \n",
       "3      7040   201.537699  1535.678036   202.336697  1535.080775   202.712908   \n",
       "4     12725   249.444091  1187.685341   249.306445  1186.087956   249.328818   \n",
       "...     ...          ...          ...          ...          ...          ...   \n",
       "3195  16905   577.724882  1380.802520   577.452172  1380.104572   577.339700   \n",
       "3196  28089   586.645465  1379.399500   586.368776  1380.394807   586.242682   \n",
       "3197   6857   597.217246  1527.064490   596.686452  1527.016874   596.350725   \n",
       "3198  16152  1745.845307   469.177597  1744.497498   468.534756  1742.896187   \n",
       "3199   4523  1988.686107   572.971326  1986.988109   572.220733  1985.476285   \n",
       "\n",
       "               v6           v7           v8           v9  ...          v51  \\\n",
       "0      484.916786  1878.297251   483.607408  1877.232523  ...  1858.267332   \n",
       "1     1037.701746   254.783283  1036.928615   254.764632  ...   255.513024   \n",
       "2      707.799349  2153.609894   707.412619  2152.675959  ...  2141.261714   \n",
       "3     1534.049328   203.145452  1533.703812   204.116087  ...   214.686196   \n",
       "4     1184.648237   249.536132  1183.043804   249.559171  ...   250.708801   \n",
       "...           ...          ...          ...          ...  ...          ...   \n",
       "3195  1379.270221   577.610687  1378.841858   577.500031  ...   577.284505   \n",
       "3196  1381.219545   586.563523  1382.421676   586.494351  ...   587.277700   \n",
       "3197  1526.527276   596.472419  1526.807906   596.089304  ...   592.180505   \n",
       "3198   468.133884  1743.119558   467.242674  1742.227691  ...  1726.336609   \n",
       "3199   571.546164  1985.628877   570.733403  1984.478573  ...  1967.803791   \n",
       "\n",
       "              v52          v53          v54          v55          v56  \\\n",
       "0      470.841380  1856.219303   469.393969  1856.552489   470.444567   \n",
       "1     1018.542852   255.457484  1017.695371   255.634974  1016.850498   \n",
       "2      697.260472  2139.560668   696.809420  2140.308635   696.350739   \n",
       "3     1522.173753   214.943301  1521.623641   215.417004  1521.138921   \n",
       "4     1155.998251   250.527023  1154.416109   250.811362  1153.720921   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "3195  1368.610978   576.965026  1367.950790   577.278280  1367.584677   \n",
       "3196  1408.285285   587.050579  1409.381164   587.417059  1410.319995   \n",
       "3197  1528.450841   591.825208  1528.542128   591.854611  1528.538372   \n",
       "3198   455.579601  1724.443274   454.601886  1725.104752   455.027369   \n",
       "3199   557.467547  1965.896364   556.623033  1966.254468   556.517922   \n",
       "\n",
       "              v57          v58          v59          v60  \n",
       "0     1855.582486   469.986863  1855.688619   468.640360  \n",
       "1      255.686676  1016.130810   255.772308  1014.982323  \n",
       "2     2139.635565   695.975627  2140.150727   695.287165  \n",
       "3      215.592934  1520.721280   215.539759  1519.745928  \n",
       "4      250.932460  1152.601370   250.994598  1150.809199  \n",
       "...           ...          ...          ...          ...  \n",
       "3195   577.261276  1367.221699   577.468860  1366.473056  \n",
       "3196   587.471244  1411.495963   587.665562  1412.260669  \n",
       "3197   591.601316  1528.647933   591.734306  1528.216409  \n",
       "3198  1724.272582   454.714193  1724.361497   453.652381  \n",
       "3199  1965.271000   556.010473  1965.609573   554.975151  \n",
       "\n",
       "[3200 rows x 61 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc.to_csv('sub_dfc.csv', index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(21.6318, dtype=torch.float64)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.MSELoss()\n",
    "m(torch.tensor(regr.predict(y_test), dtype = torch.double), torch.tensor(y_test_labels, dtype = torch.double))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
